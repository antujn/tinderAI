{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Access Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import robobrowser\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOBILE_USER_AGENT = \"Mozilla/5.0 (Linux; U; en-gb; KFTHWI Build/JDQ39) AppleWebKit/535.19 (KHTML, like Gecko) Silk/3.16 Safari/535.19\"\n",
    "FB_AUTH = \"https://www.facebook.com/v2.6/dialog/oauth?redirect_uri=fb464891386855067%3A%2F%2Fauthorize%2F&display=touch&state=%7B%22challenge%22%3A%22IUUkEUqIGud332lfu%252BMJhxL4Wlc%253D%22%2C%220_auth_logger_id%22%3A%2230F06532-A1B9-4B10-BB28-B29956C71AB1%22%2C%22com.facebook.sdk_client_state%22%3Atrue%2C%223_method%22%3A%22sfvc_auth%22%7D&scope=user_birthday%2Cuser_photos%2Cuser_education_history%2Cemail%2Cuser_relationship_details%2Cuser_friends%2Cuser_work_history%2Cuser_likes&response_type=token%2Csigned_request&default_audience=friends&return_scopes=true&auth_type=rerequest&client_id=464891386855067&ret=login&sdk=ios&logger_id=30F06532-A1B9-4B10-BB28-B29956C71AB1&ext=1470840777&hash=AeZqkIcf-NEW6vBd\"\n",
    "\n",
    "s = robobrowser.RoboBrowser(user_agent=MOBILE_USER_AGENT, parser=\"lxml\")\n",
    "s.open(FB_AUTH)\n",
    "\n",
    "# submit login form\n",
    "f = s.get_form()\n",
    "f[\"pass\"] = ?\n",
    "f[\"email\"] = ?\n",
    "s.submit_form(f)\n",
    "\n",
    "# click the 'ok' button on the dialog\n",
    "f = s.get_form()\n",
    "s.submit_form(f, submit=f.submit_fields['__CONFIRM__'])\n",
    "\n",
    "# get access token from the html response\n",
    "access_token = re.search(r\"access_token=([\\w\\d]+)\", s.response.content.decode()).groups()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynder\n",
    "import socket\n",
    "socket.setdefaulttimeout(60)\n",
    "\n",
    "from IPython.display import Image, HTML, display, clear_output\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from facenet.src import facenet\n",
    "from facenet.src.align import detect_face\n",
    "\n",
    "import imageio\n",
    "warnings.filterwarnings(\"ignore\", module=\"imageio\")\n",
    "from skimage.transform import resize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = pynder.Session(access_token)\n",
    "session.banned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Nearby Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = session.nearby_users()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Photos and Label Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('images'):\n",
    "    os.makedirs('images')\n",
    "if not os.path.exists('images/like'):\n",
    "    os.makedirs('images/like')\n",
    "if not os.path.exists('images/dislike'):\n",
    "    os.makedirs('images/dislike')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def move():\n",
    "    os.chdir(\"images\")\n",
    "    for photo in os.listdir():\n",
    "        if photo.endswith('.jpg'):\n",
    "            if res == '1':\n",
    "                os.rename(photo,'like/'+photo)\n",
    "            elif res == '2':\n",
    "                os.rename(photo,'superlike/'+photo)\n",
    "            elif res == '0':\n",
    "                os.rename(photo,'dislike/'+photo)\n",
    "    \n",
    "    os.chdir(\"..\")\n",
    "\n",
    "for g in range(1):\n",
    "    clear_output(wait=False)\n",
    "    girl = next(users)\n",
    "    print(girl.name)\n",
    "    photos = list(girl.get_photos(width=640))[:5]\n",
    "    for photo in photos:\n",
    "        urlretrieve(photo, 'images/'+str(photo).split('/')[-1])\n",
    "    photos = list(girl.get_photos(width=172))[:5]\n",
    "    imghtml=''.join( [\"<img style='float: left; margin: 0px;' src='%s'/>\" % str(photo) \n",
    "                         for photo in photos])\n",
    "    display(HTML(imghtml))\n",
    "    res = input()\n",
    "    if res == '1':\n",
    "        girl.like()\n",
    "        move()\n",
    "    elif res == '2':\n",
    "        girl.superlike()\n",
    "        move()\n",
    "    elif res == '0':\n",
    "        girl.dislike()\n",
    "        move()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Faces and Align Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('images_aligned'):\n",
    "    os.makedirs('images_aligned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = facenet.get_dataset('images')\n",
    "\n",
    "# networks and loading parameters\n",
    "with tf.Graph().as_default():\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1)\n",
    "        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n",
    "        with sess.as_default():\n",
    "            pnet, rnet, onet = detect_face.create_mtcnn(sess, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for cls in dataset:\n",
    "    if not os.path.exists(os.path.join('images_aligned', cls.name)):\n",
    "        os.makedirs(os.path.join('images_aligned', cls.name))      \n",
    "    for image_path in cls.image_paths:\n",
    "        filename = os.path.join('images_aligned', cls.name, os.path.splitext(os.path.split(image_path)[1])[0]+'.png')\n",
    "        img = imageio.imread(image_path)[:,:,0:3]\n",
    "        bb, _ = detect_face.detect_face(img, 20, pnet, rnet, onet, [0.6,0.7,0.7 ], 0.709)\n",
    "        if bb.shape[0]>0:\n",
    "            det = bb[:,0:4]\n",
    "            imgsize = np.asarray(img.shape)[0:2]\n",
    "            if bb.shape[0]>1:\n",
    "                bbsize = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\n",
    "                imgcenter = imgsize/2\n",
    "                offsets = np.vstack([ (det[:,0]+det[:,2])/2-imgcenter[1], (det[:,1]+det[:,3])/2-imgcenter[0]])\n",
    "                det = det[np.argmax(bbsize-np.sum(np.power(offsets,2.0),0)*2.0),:]\n",
    "            det = np.squeeze(det)\n",
    "            bb = np.zeros(4, dtype=np.int32)\n",
    "            bb[0] = np.maximum(det[0]-44/2, 0)\n",
    "            bb[1] = np.maximum(det[1]-44/2, 0)\n",
    "            bb[2] = np.minimum(det[2]+44/2, imgsize[1])\n",
    "            bb[3] = np.minimum(det[3]+44/2, imgsize[0])\n",
    "            cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n",
    "            scaled = resize(cropped, (182, 182), mode='constant')\n",
    "            imageio.imwrite(filename, scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = facenet.get_dataset('images_aligned')\n",
    "images, labels = facenet.get_image_paths_and_labels(train)\n",
    " \n",
    "with tf.Graph().as_default():\n",
    "    with tf.Session() as sess:\n",
    "        facenet.load_model('20180402-114759')\n",
    "\n",
    "        imgplaceholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "        embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "        phase_train = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "\n",
    "        images = facenet.load_data(images, False, False, 160)\n",
    "        feed_dict = {imgplaceholder: images, phase_train:False}\n",
    "        embeddings = sess.run(embeddings, feed_dict=feed_dict)\n",
    "\n",
    "        np.save('embeddings.npy', embeddings)\n",
    "        np.save('labels.npy', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Saved Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=np.load('embeddings.npy')\n",
    "labels=np.load('labels.npy')\n",
    "\n",
    "tinderfacenet = pd.DataFrame(embeddings)\n",
    "tinderfacenet['labels']=labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(tinderfacenet.drop(columns=['labels']), tinderfacenet['labels'], \n",
    "                                                test_size=0.3)\n",
    "trainX.shape, testX.shape, trainY.shape, testY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainY.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# model = XGBClassifier()\n",
    "# model = GradientBoostingClassifier(loss='exponential')\n",
    "model = GradientBoostingClassifier(loss='deviance')\n",
    "\n",
    "model.fit(trainX, trainY)\n",
    "print(model.score(testX, testY))\n",
    "\n",
    "preds = model.predict(testX)\n",
    "cm = confusion_matrix(testY, preds)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "recall = float(tp) / np.sum(cm,axis=1)[1]\n",
    "specificity = float(tn) /np.sum(cm,axis=1)[0]\n",
    "\n",
    "print('like accuracy: ', recall)\n",
    "print('dislike accuracy: ', specificity)\n",
    "\n",
    "# joblib.dump(model, 'GBdev_model.pkl')\n",
    "# joblib.dump(model, 'GBexp_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def create_baseline():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_dim=512, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=10, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "results = cross_val_score(estimator, trainX, trainY, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inteligent Swipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.profile.distance_filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session.update_location(LAT, LON)\n",
    "session.profile.pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('GBdev_model.pkl')\n",
    "users = session.nearby_users()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('temp'):\n",
    "    os.makedirs('temp')\n",
    "if not os.path.exists('temp_aligned'):\n",
    "    os.makedirs('temp_aligned')\n",
    "\n",
    "def clean(folder):\n",
    "    for file in os.listdir(folder):\n",
    "        os.unlink(os.path.join(folder, file))\n",
    "        \n",
    "def show():\n",
    "    photos = list(girl.get_photos(width=172))[:5]\n",
    "    imghtml=''.join( [\"<img style='float: left; margin: 0px;' src='%s'/>\" % str(photo) \n",
    "                         for photo in photos])\n",
    "    display(HTML(imghtml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1)\n",
    "    sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n",
    "    with tf.Session() as sess:\n",
    "        pnet, rnet, onet = detect_face.create_mtcnn(sess, None)\n",
    "        facenet.load_model('20180402-114759')\n",
    "        \n",
    "        for girl in users:\n",
    "            clear_output(wait=True)\n",
    "            photos = list(girl.get_photos(width=640))[:5]\n",
    "            for photo in photos:\n",
    "                urlretrieve(photo, 'temp/'+str(photo).split('/')[-1])\n",
    "            \n",
    "            for photo in os.listdir('temp'):\n",
    "                img = imageio.imread('temp/'+photo)[:,:,0:3]\n",
    "                bb, _ = detect_face.detect_face(img, 20, pnet, rnet, onet, [0.6,0.7,0.7 ], 0.709)\n",
    "                if bb.shape[0]>0:\n",
    "                    det = bb[:,0:4]\n",
    "                    imgsize = np.asarray(img.shape)[0:2]\n",
    "                    if bb.shape[0]>1:\n",
    "                        bbsize = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\n",
    "                        imgcenter = imgsize/2\n",
    "                        offsets = np.vstack([ (det[:,0]+det[:,2])/2-imgcenter[1], (det[:,1]+det[:,3])/2-imgcenter[0]])\n",
    "                        det = det[np.argmax(bbsize-np.sum(np.power(offsets,2.0),0)*2.0),:]\n",
    "                    det = np.squeeze(det)\n",
    "                    bb = np.zeros(4, dtype=np.int32)\n",
    "                    bb[0] = np.maximum(det[0]-44/2, 0)\n",
    "                    bb[1] = np.maximum(det[1]-44/2, 0)\n",
    "                    bb[2] = np.minimum(det[2]+44/2, imgsize[1])\n",
    "                    bb[3] = np.minimum(det[3]+44/2, imgsize[0])\n",
    "                    cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n",
    "                    scaled = resize(cropped, (182, 182), mode='constant')\n",
    "                    imageio.imwrite('temp_aligned/'+photo, scaled)\n",
    "\n",
    "            imgplaceholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "            embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "            phase_train = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "            if len(os.listdir('temp_aligned'))==0:\n",
    "                girl.dislike()\n",
    "                continue\n",
    "            os.chdir('temp_aligned')\n",
    "            images = facenet.load_data(os.listdir(), False, False, 160)\n",
    "            os.chdir('..')\n",
    "            feed_dict = {imgplaceholder: images, phase_train:False}\n",
    "            embeddings = pd.DataFrame(sess.run(embeddings, feed_dict=feed_dict))\n",
    "                    \n",
    "            preds = model.predict(embeddings)\n",
    "            label, counts = np.unique(preds, return_counts=True)\n",
    "            \n",
    "            dec = {}\n",
    "            dec[0]=0\n",
    "            dec[1]=0\n",
    "            dec.update(dict(zip(label, counts)))\n",
    "            \n",
    "            if dec[1]>dec[0]:\n",
    "                girl.like()\n",
    "                show()\n",
    "                print(\"liked\")\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                girl.dislike()\n",
    "                show()\n",
    "                print(\"disliked\")\n",
    "                time.sleep(5)\n",
    "            \n",
    "            clean('temp')\n",
    "            clean('temp_aligned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
